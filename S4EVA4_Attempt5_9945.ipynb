{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S4EVA4_Attempt5_9945.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajy4683/EVA4S4/blob/master/S4EVA4_Attempt5_9945.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbZiFNg_soz5",
        "colab_type": "text"
      },
      "source": [
        "### **Final Accuracy: 99.48**\n",
        "###  Number of parameters - 9122"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m2JWFliFfKT",
        "colab_type": "code",
        "outputId": "115ee655-ff1d-4232-8570-6fd49da657de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auzVE6mdHdzZ",
        "colab_type": "code",
        "outputId": "96e3115d-09c3-4f9f-d444-04ea56130ffc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "!pip install pytorch-ignite\n",
        "!pip install torchsummary\n",
        "!pip install wandb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pytorch-ignite) (1.4.0)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.6/dist-packages (0.8.26)\n",
            "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.14.1)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.5.0)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.6.1)\n",
            "Requirement already satisfied: watchdog>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.10.2)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.352.0)\n",
            "Requirement already satisfied: gql==0.2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.2.0)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.0.7)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.21.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.14.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (4.0.2)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.0)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (2019.11.28)\n",
            "Requirement already satisfied: pathtools>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from watchdog>=0.8.3->wandb) (0.1.2)\n",
            "Requirement already satisfied: graphql-core<2,>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb) (1.1)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb) (2.3)\n",
            "Requirement already satisfied: gitdb2>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from GitPython>=1.0.0->wandb) (2.0.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2.8)\n",
            "Requirement already satisfied: smmap2>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from gitdb2>=2.0.0->GitPython>=1.0.0->wandb) (2.0.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXqF5fu1mV8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
        "from ignite.metrics import Accuracy, Loss\n",
        "from torch.utils.data import DataLoader\n",
        "from ignite.handlers import Checkpoint, DiskSaver\n",
        "\n",
        "\n",
        "import logging\n",
        "logging.propagate = False \n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "\n",
        "from argparse import ArgumentParser\n",
        "from tqdm import tqdm\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N8hW64W9CHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logging.propagate = False \n",
        "logging.getLogger().setLevel(logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWIjKEiV7azI",
        "colab_type": "code",
        "outputId": "e8778eab-415d-4a3c-a822-b571213b5a01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import wandb\n",
        "#wandb.init()\n",
        "!wandb login a6f947d2d2f69e7a8c8ca0f69811fd554f27d204\n",
        "#wandb login a6f947d2d2f69e7a8c8ca0f69811fd554f27d204"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OONup7Ukaulv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05CxdNgXsRnF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.dropout_val = 0.1\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.Dropout(self.dropout_val),\n",
        "            nn.Conv2d(8, 8, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.MaxPool2d(2, 2),            \n",
        "            nn.Dropout(self.dropout_val)\n",
        "        )\n",
        "        \n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(8, 16, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(self.dropout_val),\n",
        "            nn.Conv2d(16, 16, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(self.dropout_val)\n",
        "        )\n",
        "        \n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(16, 16, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(self.dropout_val),\n",
        "            nn.Conv2d(16, 16, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(self.dropout_val)\n",
        "        )\n",
        "        \n",
        "        self.gap_linear = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Conv2d(16, 10, 1)\n",
        "        )\n",
        "                \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        \n",
        "        #x = x.view(x.size(0), -1)\n",
        "        x = self.gap_linear(x)\n",
        "        x = x.view(-1, 10)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Cx9q2QFgM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(Net, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(1, 8, 3, padding=1) #input -? OUtput? RF\n",
        "#         self.conv1_bn = nn.BatchNorm2d(8)\n",
        "#         self.dropout_val = 0.00001\n",
        "#         self.conv2 = nn.Conv2d(8, 16, 3, padding=1)\n",
        "#         self.conv2_bn = nn.BatchNorm2d(16)\n",
        "#         self.pool1 = nn.MaxPool2d(2, 2)\n",
        "#         self.conv3 = nn.Conv2d(16, 16, 3, padding=1)\n",
        "#         self.conv3_bn = nn.BatchNorm2d(16)\n",
        "#         self.conv4 = nn.Conv2d(16, 16, 3, padding=1)\n",
        "#         self.conv4_bn = nn.BatchNorm2d(16)\n",
        "#         self.pool2 = nn.MaxPool2d(2, 2)\n",
        "#         self.conv5 = nn.Conv2d(16, 16, 3)\n",
        "#         self.conv5_bn = nn.BatchNorm2d(16)\n",
        "#         self.conv6 = nn.Conv2d(16, 16, 3)\n",
        "#         self.conv6_bn = nn.BatchNorm2d(16)\n",
        "\n",
        "#         self.conv7 = nn.Conv2d(16, 10, 1)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "#         # x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
        "#         # x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
        "#         # x = F.relu(self.conv7(x))\n",
        "#         # x = x.view(-1, 10)\n",
        "#         # return F.log_softmax(x)\n",
        "        \n",
        "\n",
        "#         # x = F.dropout2d(self.conv1_bn(F.relu(self.conv1(x))),self.dropout_val) ### Layer 1 ---->(Relu(BN(Conv)))\n",
        "#         # x = self.pool1(F.dropout2d(self.conv2_bn(F.relu(self.conv2(x))),self.dropout_val)) ### Layer 2---> MaxPool((Relu(BN(Conv))))\n",
        "#         # x = F.dropout2d(self.conv3_bn(F.relu(self.conv3(x))),self.dropout_val) ### Layer 3 ---->(Relu(BN(Conv)))\n",
        "#         # x = self.pool2(F.dropout2d(self.conv4_bn(F.relu(self.conv4(x))),self.dropout_val)) ### Layer 4---> MaxPool((Relu(BN(Conv))))\n",
        "#         # #########\n",
        "#         # x = F.dropout2d(self.conv5_bn(F.relu(self.conv5(x))),self.dropout_val) ### Layer 5---> (Relu(BN(Conv)))        \n",
        "#         # #x = F.adaptive_avg_pool2d(F.relu(self.conv6_bn(self.conv6(x))),(1,1))### Layer 6 ---> (Relu(BN(Conv))) F.adaptive_avg_pool2d(x, (1, 1))\n",
        "#         # x = F.dropout2d(self.conv6_bn(F.relu(self.conv6(x))),self.dropout_val)\n",
        "#         # x = F.adaptive_avg_pool2d(x, (1, 1))\n",
        "#         # #F.avg_pool2d(x,x.size()[2:])### Layer 6 ---> (Relu(BN(Conv))) F.adaptive_avg_pool2d(x, (1, 1))\n",
        "#         # x = self.conv7(x) #### Final Layer (Conv)\n",
        "#         # x = x.view(-1, 10)\n",
        "\n",
        "\n",
        "#         x = F.relu(self.conv1_bn(self.conv1(x))) ### Layer 1 ---->(Relu(BN(Conv)))\n",
        "#         x = self.pool1(F.relu(self.conv2_bn(self.conv2(x)))) ### Layer 2---> MaxPool((Relu(BN(Conv))))\n",
        "#         x = F.relu(self.conv3_bn(self.conv3(x))) ### Layer 3 ---->(Relu(BN(Conv)))\n",
        "#         x = self.pool2(F.relu(self.conv4_bn(self.conv4(x)))) ### Layer 4---> MaxPool((Relu(BN(Conv))))\n",
        "#         #########\n",
        "#         x = F.relu(self.conv5_bn(self.conv5(x))) ### Layer 5---> (Relu(BN(Conv)))        \n",
        "#         #x = F.adaptive_avg_pool2d(F.relu(self.conv6_bn(self.conv6(x))),(1,1))### Layer 6 ---> (Relu(BN(Conv))) F.adaptive_avg_pool2d(x, (1, 1))\n",
        "#         x = F.relu(self.conv6_bn(self.conv6(x)))\n",
        "#         x = F.adaptive_avg_pool2d(x, (1, 1))\n",
        "#         #F.avg_pool2d(x,x.size()[2:])### Layer 6 ---> (Relu(BN(Conv))) F.adaptive_avg_pool2d(x, (1, 1))\n",
        "#         x = self.conv7(x) #### Final Layer (Conv)\n",
        "#         x = x.view(-1, 10)\n",
        "#         return F.log_softmax(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq90DPycyR0x",
        "colab_type": "code",
        "outputId": "50497132-54fd-4200-8a76-8f54bfd634d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Net"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__main__.Net"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ediZhP_nRWG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class Net(nn.Module):\n",
        "#     def __init__(self,start_channels=32, exponetate_layers=True):\n",
        "#         super(Net, self).__init__()\n",
        "#         self.start_channels = start_channels\n",
        "#         self.multiplier = 2\n",
        "\n",
        "#         if (exponetate_layers == False):\n",
        "#             self.multiplier = 1\n",
        "        \n",
        "#         self.conv1 = nn.Conv2d(1, self.start_channels, 3, padding=1) #input -? OUtput? RF\n",
        "#         self.conv1_bn = nn.BatchNorm2d(self.start_channels)\n",
        "#         self.conv2 = nn.Conv2d(self.start_channels, self.start_channels*self.multiplier, 3, padding=1)\n",
        "#         self.conv2_bn = nn.BatchNorm2d(self.start_channels*self.multiplier)\n",
        "\n",
        "#         self.start_channels = self.start_channels * self.multiplier\n",
        "#         self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "#         self.conv3 = nn.Conv2d(self.start_channels, self.start_channels*self.multiplier, 3, padding=1)\n",
        "#         self.conv3_bn = nn.BatchNorm2d(self.start_channels*self.multiplier)\n",
        "#         #self.start_channels = self.start_channels * self.multiplier\n",
        "#         self.conv4 = nn.Conv2d(self.start_channels, self.start_channels*self.multiplier, 3, padding=1)\n",
        "#         self.conv4_bn = nn.BatchNorm2d(self.start_channels*self.multiplier)\n",
        "#         #self.start_channels = self.start_channels * self.multiplier\n",
        "#         self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "\n",
        "#         # self.conv5 = nn.Conv2d(self.start_channels, self.start_channels*self.multiplier, 3)\n",
        "#         # self.conv5_bn = nn.BatchNorm2d(self.start_channels*self.multiplier)\n",
        "#         # #self.start_channels = self.start_channels * self.multiplier\n",
        "#         # self.conv6 = nn.Conv2d(self.start_channels, self.start_channels*self.multiplier, 3)\n",
        "#         # self.conv6_bn = nn.BatchNorm2d(self.start_channels*self.multiplier)\n",
        "#         # #self.start_channels = self.start_channels * self.multiplier\n",
        "\n",
        "#         # self.conv7 = nn.Conv2d(self.start_channels, 10, 1)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.relu(self.conv1_bn(self.conv1(x))) ### Layer 1 ---->(Relu(BN(Conv)))\n",
        "#         x = self.pool1(F.relu(self.conv2_bn(self.conv2(x)))) ### Layer 2---> MaxPool((Relu(BN(Conv))))\n",
        "#         x = F.relu(self.conv3_bn(self.conv3(x))) ### Layer 3 ---->(Relu(BN(Conv)))\n",
        "#         x = self.pool2(F.relu(self.conv4_bn(self.conv4(x)))) ### Layer 4---> MaxPool((Relu(BN(Conv))))\n",
        "#         #########\n",
        "#         x = F.relu(self.conv5_bn(self.conv5(x))) ### Layer 5---> (Relu(BN(Conv)))        \n",
        "#         #x = F.adaptive_avg_pool2d(F.relu(self.conv6_bn(self.conv6(x))),(1,1))### Layer 6 ---> (Relu(BN(Conv))) F.adaptive_avg_pool2d(x, (1, 1))\n",
        "#         x = F.relu(self.conv6_bn(self.conv6(x)))\n",
        "#         x = F.avg_pool2d(x,x.size()[2:])### Layer 6 ---> (Relu(BN(Conv))) F.adaptive_avg_pool2d(x, (1, 1))\n",
        "#         x = self.conv7(x) #### Final Layer (Conv)\n",
        "#         x = x.view(-1, 10)\n",
        "#         return F.log_softmax(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xdydjYTZFyi3",
        "colab": {}
      },
      "source": [
        "# model = Net(start_channels=8,exponetate_layers=True).to(device)\n",
        "# summary(model, input_size=(1, 28, 28))\n",
        "# #wandb.watch(model, log=\"all\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU0GFDJNJXWS",
        "colab_type": "code",
        "outputId": "84def7d0-a4ac-4d08-ce44-779f3d443430",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        }
      },
      "source": [
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 28, 28]              80\n",
            "              ReLU-2            [-1, 8, 28, 28]               0\n",
            "       BatchNorm2d-3            [-1, 8, 28, 28]              16\n",
            "           Dropout-4            [-1, 8, 28, 28]               0\n",
            "            Conv2d-5            [-1, 8, 28, 28]             584\n",
            "              ReLU-6            [-1, 8, 28, 28]               0\n",
            "       BatchNorm2d-7            [-1, 8, 28, 28]              16\n",
            "         MaxPool2d-8            [-1, 8, 14, 14]               0\n",
            "           Dropout-9            [-1, 8, 14, 14]               0\n",
            "           Conv2d-10           [-1, 16, 14, 14]           1,168\n",
            "             ReLU-11           [-1, 16, 14, 14]               0\n",
            "      BatchNorm2d-12           [-1, 16, 14, 14]              32\n",
            "          Dropout-13           [-1, 16, 14, 14]               0\n",
            "           Conv2d-14           [-1, 16, 14, 14]           2,320\n",
            "             ReLU-15           [-1, 16, 14, 14]               0\n",
            "      BatchNorm2d-16           [-1, 16, 14, 14]              32\n",
            "        MaxPool2d-17             [-1, 16, 7, 7]               0\n",
            "          Dropout-18             [-1, 16, 7, 7]               0\n",
            "           Conv2d-19             [-1, 16, 5, 5]           2,320\n",
            "             ReLU-20             [-1, 16, 5, 5]               0\n",
            "      BatchNorm2d-21             [-1, 16, 5, 5]              32\n",
            "          Dropout-22             [-1, 16, 5, 5]               0\n",
            "           Conv2d-23             [-1, 16, 3, 3]           2,320\n",
            "             ReLU-24             [-1, 16, 3, 3]               0\n",
            "      BatchNorm2d-25             [-1, 16, 3, 3]              32\n",
            "        MaxPool2d-26             [-1, 16, 1, 1]               0\n",
            "          Dropout-27             [-1, 16, 1, 1]               0\n",
            "AdaptiveAvgPool2d-28             [-1, 16, 1, 1]               0\n",
            "           Conv2d-29             [-1, 10, 1, 1]             170\n",
            "================================================================\n",
            "Total params: 9,122\n",
            "Trainable params: 9,122\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.55\n",
            "Params size (MB): 0.03\n",
            "Estimated Total Size (MB): 0.59\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3YKrywtQrSc",
        "colab_type": "code",
        "outputId": "3e281a76-2753-48a5-a1bb-30fb02e88981",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_loader.dataset.data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
        "\n",
        "from tqdm import tqdm\n",
        "def train(args, model, device, train_loader, optimizer, epoch_number):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    train_loss = 0\n",
        "    train_accuracy = 0\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "        train_accuracy += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    print('\\nEpoch: {:.0f} Train set: Average loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
        "        epoch_number, train_loss, train_accuracy, len(train_loader.dataset),\n",
        "        100. * train_accuracy / len(train_loader.dataset)))\n",
        "    \n",
        "    wandb.log({        \n",
        "        \"Train Accuracy\": 100. * train_accuracy / len(train_loader.dataset),\n",
        "        \"Train Loss\": train_loss})\n",
        "\n",
        "\n",
        "def test(args, model, device, test_loader,classes,epoch_number):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    example_images = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        #example_images.append(wandb.Image(\n",
        "        #        data[0], caption=\"Pred: {} Truth: {}\".format(classes[pred[0].item()], classes[target[0]])))\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nEpoch: {:.0f} Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
        "        epoch_number, test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    \n",
        "    wandb.log({\n",
        "        \"Test Accuracy\": 100. * correct / len(test_loader.dataset),\n",
        "        \"Test Loss\": test_loss})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So5uk4EkHW6R",
        "colab_type": "code",
        "outputId": "a09c472b-f35f-4053-f610-f999fbe40e9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#model = Net(start_channels=16,exponetate_layers=False).to(device)\n",
        "wandb.init(project=\"news4eva4\")\n",
        "wandb.watch_called = False # Re-run the model without restarting the runtime, unnecessary after our next release\n",
        "\n",
        "# WandB – Config is a variable that holds and saves hyperparameters and inputs\n",
        "config = wandb.config          # Initialize config\n",
        "config.batch_size = 64          # input batch size for training (default: 64)\n",
        "config.test_batch_size = config.batch_size    # input batch size for testing (default: 1000)\n",
        "config.epochs = 20             # number of epochs to train (default: 10)\n",
        "config.lr = 0.01               # learning rate (default: 0.01)\n",
        "config.momentum = 0.9          # SGD momentum (default: 0.5) \n",
        "config.no_cuda = False         # disables CUDA training\n",
        "config.seed = 1               # random seed (default: 42)\n",
        "config.log_interval = 10     # how many batches to wait before logging training status\n",
        "\n",
        "def main():\n",
        "    use_cuda = not config.no_cuda and torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "    \n",
        "    # Set random seeds and deterministic pytorch for reproducibility\n",
        "    # random.seed(config.seed)       # python random seed\n",
        "    torch.manual_seed(config.seed) # pytorch random seed\n",
        "    # numpy.random.seed(config.seed) # numpy random seed\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    # Load the dataset: We're training our CNN on CIFAR10 (https://www.cs.toronto.edu/~kriz/cifar.html)\n",
        "    # First we define the tranformations to apply to our images\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', train=True, download=True,\n",
        "                        transform=transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.1307,), (0.3081,))\n",
        "                        ])),\n",
        "        batch_size=config.batch_size, shuffle=True, **kwargs)\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.1307,), (0.3081,))\n",
        "                        ])),\n",
        "        batch_size=config.batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "    # Initialize our model, recursively go over all modules and convert their parameters and buffers to CUDA tensors (if device is set to cuda)\n",
        "    model = Net().to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=config.lr,\n",
        "                          momentum=config.momentum)\n",
        "    \n",
        "    # WandB – wandb.watch() automatically fetches all layer dimensions, gradients, model parameters and logs them automatically to your dashboard.\n",
        "    # Using log=\"all\" log histograms of parameter values in addition to gradients\n",
        "    wandb.watch(model, log=\"all\")\n",
        "\n",
        "    for epoch in range(1, config.epochs + 1):\n",
        "        train(config, model, device, train_loader, optimizer, epoch)\n",
        "        test(config, model, device, test_loader, classes,epoch)\n",
        "        \n",
        "    # WandB – Save the model checkpoint. This automatically saves a file to the cloud and associates it with the current run.\n",
        "    torch.save(model.state_dict(), \"model.h5\")\n",
        "    wandb.save('model.h5')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# model = Net().to(device)\n",
        "# summary(model, input_size=(1, 28, 28))\n",
        "\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "# wandb.watch(model, log=\"all\")\n",
        "# for epoch in range(1, 20):\n",
        "#     train(model, device, train_loader, optimizer, epoch)\n",
        "#     test(model, device, test_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/rajy4683/news4eva4\" target=\"_blank\">https://app.wandb.ai/rajy4683/news4eva4</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/rajy4683/news4eva4/runs/1i1ns4m1\" target=\"_blank\">https://app.wandb.ai/rajy4683/news4eva4/runs/1i1ns4m1</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.037439361214637756 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 55.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1 Train set: Average loss: 0.0038, Accuracy: 55658/60000 (92.763%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1 Test set: Average loss: 0.0493, Accuracy: 9844/10000 (98.440%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.02039620280265808 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 55.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 2 Train set: Average loss: 0.0014, Accuracy: 58381/60000 (97.302%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 2 Test set: Average loss: 0.0340, Accuracy: 9885/10000 (98.850%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.02358873188495636 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 56.97it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 3 Train set: Average loss: 0.0011, Accuracy: 58718/60000 (97.863%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 3 Test set: Average loss: 0.0297, Accuracy: 9899/10000 (98.990%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.000861242413520813 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 56.20it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 4 Train set: Average loss: 0.0010, Accuracy: 58888/60000 (98.147%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 4 Test set: Average loss: 0.0280, Accuracy: 9909/10000 (99.090%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.02046094834804535 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 55.46it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 5 Train set: Average loss: 0.0009, Accuracy: 58972/60000 (98.287%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 5 Test set: Average loss: 0.0236, Accuracy: 9916/10000 (99.160%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.0187130868434906 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 55.65it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 6 Train set: Average loss: 0.0008, Accuracy: 59027/60000 (98.378%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 6 Test set: Average loss: 0.0239, Accuracy: 9920/10000 (99.200%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.2213306725025177 batch_id=937: 100%|██████████| 938/938 [00:17<00:00, 49.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 7 Train set: Average loss: 0.0008, Accuracy: 59133/60000 (98.555%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 7 Test set: Average loss: 0.0204, Accuracy: 9929/10000 (99.290%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.01403738558292389 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 55.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 8 Train set: Average loss: 0.0007, Accuracy: 59154/60000 (98.590%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 8 Test set: Average loss: 0.0227, Accuracy: 9925/10000 (99.250%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.12039291113615036 batch_id=937: 100%|██████████| 938/938 [00:17<00:00, 54.39it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 9 Train set: Average loss: 0.0007, Accuracy: 59212/60000 (98.687%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 9 Test set: Average loss: 0.0214, Accuracy: 9928/10000 (99.280%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.11942537128925323 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 56.30it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 10 Train set: Average loss: 0.0006, Accuracy: 59285/60000 (98.808%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 10 Test set: Average loss: 0.0178, Accuracy: 9946/10000 (99.460%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.20631961524486542 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 56.37it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 11 Train set: Average loss: 0.0006, Accuracy: 59259/60000 (98.765%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 11 Test set: Average loss: 0.0192, Accuracy: 9938/10000 (99.380%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.0033655762672424316 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 55.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 12 Train set: Average loss: 0.0006, Accuracy: 59247/60000 (98.745%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 12 Test set: Average loss: 0.0183, Accuracy: 9948/10000 (99.480%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.0960254892706871 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 55.54it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 13 Train set: Average loss: 0.0006, Accuracy: 59318/60000 (98.863%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 13 Test set: Average loss: 0.0172, Accuracy: 9939/10000 (99.390%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.11118742823600769 batch_id=937: 100%|██████████| 938/938 [00:17<00:00, 53.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 14 Train set: Average loss: 0.0006, Accuracy: 59342/60000 (98.903%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 14 Test set: Average loss: 0.0179, Accuracy: 9943/10000 (99.430%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.007760286331176758 batch_id=937: 100%|██████████| 938/938 [00:17<00:00, 54.09it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 15 Train set: Average loss: 0.0006, Accuracy: 59313/60000 (98.855%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 15 Test set: Average loss: 0.0187, Accuracy: 9940/10000 (99.400%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.01778198778629303 batch_id=937: 100%|██████████| 938/938 [00:17<00:00, 54.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 16 Train set: Average loss: 0.0005, Accuracy: 59385/60000 (98.975%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 16 Test set: Average loss: 0.0185, Accuracy: 9936/10000 (99.360%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.00169411301612854 batch_id=937: 100%|██████████| 938/938 [00:17<00:00, 54.13it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 17 Train set: Average loss: 0.0006, Accuracy: 59319/60000 (98.865%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 17 Test set: Average loss: 0.0204, Accuracy: 9940/10000 (99.400%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.011921197175979614 batch_id=937: 100%|██████████| 938/938 [00:17<00:00, 53.61it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 18 Train set: Average loss: 0.0005, Accuracy: 59378/60000 (98.963%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 18 Test set: Average loss: 0.0174, Accuracy: 9943/10000 (99.430%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.0128394216299057 batch_id=937: 100%|██████████| 938/938 [00:17<00:00, 54.54it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 19 Train set: Average loss: 0.0005, Accuracy: 59402/60000 (99.003%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 19 Test set: Average loss: 0.0173, Accuracy: 9946/10000 (99.460%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.0012746304273605347 batch_id=937: 100%|██████████| 938/938 [00:17<00:00, 53.53it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 20 Train set: Average loss: 0.0005, Accuracy: 59398/60000 (98.997%)\n",
            "\n",
            "\n",
            "Epoch: 20 Test set: Average loss: 0.0172, Accuracy: 9946/10000 (99.460%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm4WvEu5chGY",
        "colab_type": "text"
      },
      "source": [
        "Results of various runs are logged on the below link\n",
        "##### https://app.wandb.ai/rajy4683/news4eva4?workspace=user-rajy4683\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNbXy0l644Vr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import IFrame\n",
        "\n",
        "IFrame(src='https://app.wandb.ai/rajy4683/news4eva4/runs/r06vb1q0?workspace=user-rajy4683',width=700, height=600)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H6n18QPxaBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_metrics(metrics_dataframe_local):\n",
        "    dataset_metrics = metrics_dataframe_local.loc[:,['Test Accuracy', 'Test Loss']].dropna().reset_index().drop(columns='index')\n",
        "    final_run_metrics = pd.concat([metrics_dataframe.loc[:,['Train Accuracy', 'Train Loss']].dropna().reset_index().drop(columns='index'), \n",
        "                                   metrics_dataframe.loc[:,['Test Accuracy', 'Test Loss']].dropna().reset_index().drop(columns='index')],axis=1)\n",
        "    final_run_metrics.loc[:,['Train Accuracy', 'Test Accuracy']].plot()\n",
        "    final_run_metrics.loc[:,['Train Loss', 'Test Loss']].plot()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzzHUsobcLMR",
        "colab_type": "text"
      },
      "source": [
        "RESULTS of the Final Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrZdlGNFx16L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wandb\n",
        "api = wandb.Api()\n",
        "\n",
        "# run is specified by <entity>/<project>/<run id>\n",
        "run = api.run(\"rajy4683/news4eva4/1i1ns4m1\")\n",
        "\n",
        "# save the metrics for the run to a csv file\n",
        "metrics_dataframe = run.history()\n",
        "metrics_dataframe.to_csv(\"metrics.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4j6d7md7Wcm",
        "colab_type": "code",
        "outputId": "09bb32ba-0425-4a4e-cd4d-58ebd6c7e485",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "plot_metrics(metrics_dataframe)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMcZEqP8PNnpREaW7j/gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nd0FrP3xxDLMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-ht66kR7YM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YP5srrV6fYQo",
        "colab_type": "text"
      },
      "source": [
        "    #### First attempt ####\n",
        "    1. No doubling of layers\n",
        "    2. Use 16 input channels for all layers\n",
        "    3. Include BN.\n",
        "    4. Max Accuracy = 99.48% within 20 Epochs\n",
        "    5. Total params: 13,402\n",
        "    #### 2nd attempt ####\n",
        "    1. Swapped the last layers with GAP and 1x1 conv\n",
        "    2. Max Accuracy = 99.46 within 20 Epochs\n",
        "    3. Total params: 12122\n",
        "    #### 3rd attempt ####\n",
        "    1. Used 8 channels in first layer and 16 in the rest\n",
        "    2. Max Accuracy = 99.43 within 20 Epochs\n",
        "    3. Total params: 10,874\n",
        "    #### 4th attempt ####\n",
        "    1. Used 8 channels in first layer and 16 in the rest\n",
        "    2. Max Accuracy = 99.41 within 20 Epochs\n",
        "    3. Total params: 10,874\n",
        "    4. Moved BN after RelU\n",
        "    5. Training accurac\n",
        "    #### 5th attempt ####\n",
        "    1. Used 8 channels in first 2 layers\n",
        "    2. Introduced Dropout after major Conv layers, as there was large delta between Training Accuracy and Test Accuracy\n",
        "    3. Changed overall model to use nn.Sequential functions\n",
        "    2. Max Accuracy = 99.48 within 20 Epochs\n",
        "    3. Total params: 9122"
      ]
    }
  ]
}